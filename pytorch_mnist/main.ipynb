{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils\n",
    "import model\n",
    "import train_utils\n",
    "import plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "mnist_train = data_utils.load_train_data()\n",
    "# Load validation data\n",
    "mnist_val = data_utils.load_validation_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model\n",
    "net = model.MNISTNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'rebuild_typed_storage_child' on <module 'torch.multiprocessing.reductions' from '/Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/multiprocessing/reductions.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/Mudi/Programming/MyCode/Deep Learning/Udemy Courses/PyTorch_Deep Learning with PyTorch - Masterclass!/mnist_pytorch/main.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/main.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/main.ipynb#ch0000003?line=1'>2</a>\u001b[0m output \u001b[39m=\u001b[39m train_utils\u001b[39m.\u001b[39;49mtrain(net, mnist_train, mnist_val)\n",
      "File \u001b[0;32m~/Programming/MyCode/Deep Learning/Udemy Courses/PyTorch_Deep Learning with PyTorch - Masterclass!/mnist_pytorch/train_utils.py:38\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_data, valid_data)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/train_utils.py?line=33'>34</a>\u001b[0m iterations \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='file:///Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/train_utils.py?line=35'>36</a>\u001b[0m net\u001b[39m.\u001b[39mtrain()                   \u001b[39m# Put the network into training mode\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/train_utils.py?line=37'>38</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (items, classes) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(mnist_train_loader):\n\u001b[1;32m     <a href='file:///Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/train_utils.py?line=38'>39</a>\u001b[0m     \n\u001b[1;32m     <a href='file:///Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/train_utils.py?line=39'>40</a>\u001b[0m     \u001b[39m# Convert torch tensor to Variable\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/train_utils.py?line=40'>41</a>\u001b[0m     items \u001b[39m=\u001b[39m Variable(items)\n\u001b[1;32m     <a href='file:///Users/Mudi/Programming/MyCode/Deep%20Learning/Udemy%20Courses/PyTorch_Deep%20Learning%20with%20PyTorch%20-%20Masterclass%21/mnist_pytorch/train_utils.py?line=41'>42</a>\u001b[0m     classes \u001b[39m=\u001b[39m Variable(classes)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1186\u001b[0m, in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1176'>1177</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1177'>1178</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1178'>1179</a>\u001b[0m         \u001b[39m# If the worker responsible for `self._rcvd_idx` has already ended\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1179'>1180</a>\u001b[0m         \u001b[39m# and was unable to fulfill this task (due to exhausting an `IterableDataset`),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1183'>1184</a>\u001b[0m         \u001b[39m# call and `_IterableDatasetStopIteration` check below can mark\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1184'>1185</a>\u001b[0m         \u001b[39m# extra worker(s) as dead.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1185'>1186</a>\u001b[0m         \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_idx:\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1186'>1187</a>\u001b[0m             info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx]\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1187'>1188</a>\u001b[0m             worker_id \u001b[39m=\u001b[39m info[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1152\u001b[0m, in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1044'>1045</a>\u001b[0m             raise\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1046'>1047</a>\u001b[0m # NOTE [ DataLoader on Linux and open files limit ]\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1047'>1048</a>\u001b[0m #\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1048'>1049</a>\u001b[0m # On Linux when DataLoader is used with multiprocessing we pass the data between\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1140'>1141</a>\u001b[0m # 3. Run the script with the `send` option in the second shell:\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1141'>1142</a>\u001b[0m # (shell2) ./test_socket.py sock_tmp 1017 send\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1143'>1144</a>\u001b[0m     def _get_data(self):\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1144'>1145</a>\u001b[0m         # Fetches data from `self._data_queue`.\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1145'>1146</a>\u001b[0m         #\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1146'>1147</a>\u001b[0m         # We check workers' status every `MP_STATUS_CHECK_INTERVAL` seconds,\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1147'>1148</a>\u001b[0m         # which we achieve by running `self._try_get_data(timeout=MP_STATUS_CHECK_INTERVAL)`\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1148'>1149</a>\u001b[0m         # in a loop. This is the only mechanism to detect worker failures for\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1149'>1150</a>\u001b[0m         # Windows. For other platforms, a SIGCHLD handler is also used for\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1150'>1151</a>\u001b[0m         # worker failure detection.\n\u001b[0;32m-> <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1151'>1152</a>\u001b[0m         #\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1152'>1153</a>\u001b[0m         # If `pin_memory=True`, we also need check if `pin_memory_thread` had\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1153'>1154</a>\u001b[0m         # died at timeouts.\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1154'>1155</a>\u001b[0m         if self._timeout > 0:\n\u001b[1;32m   <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=1155'>1156</a>\u001b[0m             success, data = self._try_get_data(self._timeout)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:990\u001b[0m, in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=987'>988</a>\u001b[0m resume_iteration_cnt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers\n\u001b[1;32m    <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=988'>989</a>\u001b[0m \u001b[39mwhile\u001b[39;00m resume_iteration_cnt \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=989'>990</a>\u001b[0m     return_idx, return_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n\u001b[1;32m    <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=990'>991</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(return_idx, _utils\u001b[39m.\u001b[39mworker\u001b[39m.\u001b[39m_ResumeIteration):\n\u001b[1;32m    <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=991'>992</a>\u001b[0m         \u001b[39massert\u001b[39;00m return_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/multiprocessing/queues.py?line=119'>120</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/multiprocessing/queues.py?line=120'>121</a>\u001b[0m \u001b[39m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/multiprocessing/queues.py?line=121'>122</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39;49mloads(res)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'rebuild_typed_storage_child' on <module 'torch.multiprocessing.reductions' from '/Users/Mudi/opt/miniconda3/envs/ml/lib/python3.9/site-packages/torch/multiprocessing/reductions.py'>"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model\n",
    "output = train_utils.train(net, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_loss(output[\"train_loss\"], output[\"valid_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_loss(output[\"train_accuracy\"], output[\"valid_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load test data\n",
    "\n",
    "# Test with trained model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb029c8bf163ccaaeccce1a47db564d7b63a08f8fb4d78818e645f4541a05c52"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
